"""
Scanner Settings - PHASE 3 COMPLETE
Three optimization levels for 8GB VRAM systems
Default: Option A (safest)
"""

import torch

# =============================================================================
# PHASE 3 CONFIGURATION - CHOOSE YOUR OPTIMIZATION LEVEL
# =============================================================================

# Select your Phase 3 optimization level:
# "A" = Safe (default) - Enhanced analysis, custom violence detector (+10-13% accuracy, 3.2GB VRAM)
# "B" = Balanced - Option A + quantization + batch processing (+10-15% accuracy, 2GB VRAM)
# "C" = Maximum - Option B + quantized Llama Guard (+15-20% accuracy, 2.5GB VRAM)

PHASE3_LEVEL = "A"  # Change to "B" or "C" to try other optimization levels


# =============================================================================
# HARDWARE DETECTION
# =============================================================================

HAS_GPU = torch.cuda.is_available()

if HAS_GPU:
    vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    HAS_ENOUGH_VRAM = vram_gb >= 8.0
else:
    vram_gb = 0
    HAS_ENOUGH_VRAM = False


# =============================================================================
# PHASE 3 FEATURES BY LEVEL
# =============================================================================

# Option A Features (Default - Safe for all 8GB systems)
ENHANCED_KEYWORD_ANALYSIS = PHASE3_LEVEL in ["A", "B", "C"]
IMPROVED_CONFIDENCE_SCORING = PHASE3_LEVEL in ["A", "B", "C"]
CUSTOM_VIOLENCE_DETECTOR = PHASE3_LEVEL in ["A", "B", "C"]
SMART_CACHING = PHASE3_LEVEL in ["A", "B", "C"]

# Option B Features (Efficiency improvements)
USE_MODEL_QUANTIZATION = PHASE3_LEVEL in ["B", "C"]
QUANTIZATION_BITS = 8 if PHASE3_LEVEL == "B" else 4  # 8-bit for B, 4-bit for C
BATCH_PROCESSING = PHASE3_LEVEL in ["B", "C"]
BATCH_SIZE = 4

# Option C Features (Maximum features)
USE_QUANTIZED_LLAMA_GUARD = PHASE3_LEVEL == "C"


# =============================================================================
# CONFIDENCE LEVEL THRESHOLDS
# =============================================================================

CONFIDENCE_LEVELS = {
    "high": 0.7,
    "moderate": 0.55,
    "low": 0.5
}

MINIMUM_CONFIDENCE_THRESHOLD = CONFIDENCE_LEVELS["low"]


# =============================================================================
# CONTEXT SETTINGS
# =============================================================================

CONTEXT_PARAGRAPHS_BEFORE = 2
CONTEXT_PARAGRAPHS_AFTER = 2
MINIMUM_PARAGRAPH_LENGTH = 20


# =============================================================================
# TEXT EXCERPT SETTINGS
# =============================================================================

TEXT_EXCERPT_MAX_LENGTH = 150


# =============================================================================
# AI MODEL SETTINGS
# =============================================================================

USE_GPU_IF_AVAILABLE = True

# Core Models (always enabled)
TOXICITY_MODEL = "unitary/toxic-bert"
USE_TOXICITY_MODEL = True

HATE_SPEECH_MODEL = "facebook/roberta-hate-speech-dynabench-r4-target"
USE_HATE_SPEECH_MODEL = True

SENTIMENT_MODEL = "cardiffnlp/twitter-roberta-base-sentiment-latest"
USE_SENTIMENT_MODEL = True

# Phase 3: Custom Violence Detector (Option A+)
VIOLENCE_DETECTOR_MODEL = "distilbert-base-uncased"  # We'll fine-tune this
USE_VIOLENCE_DETECTOR = CUSTOM_VIOLENCE_DETECTOR

# Large Models (disabled by default for 8GB VRAM)
SHIELDGEMMA_MODEL = "google/shieldgemma-2b"
LLAMA_GUARD_MODEL = "meta-llama/Llama-Guard-3-1B"

# Only enable if high VRAM and not using quantized version
if HAS_GPU and HAS_ENOUGH_VRAM and vram_gb >= 12.0:
    USE_SHIELDGEMMA = True
    USE_LLAMA_GUARD = True
else:
    USE_SHIELDGEMMA = False
    USE_LLAMA_GUARD = USE_QUANTIZED_LLAMA_GUARD  # Use quantized version in Option C


# =============================================================================
# LLAMA GUARD SETTINGS
# =============================================================================

LLAMA_GUARD_HIGH_CONFIDENCE_ONLY = True
LLAMA_GUARD_CONFIDENCE_THRESHOLD = 0.7
LLAMA_GUARD_CATEGORIES = ["S1", "S3", "S4", "S9", "S10", "S11"]


# =============================================================================
# OUTPUT SETTINGS
# =============================================================================

INPUT_FOLDER = "books"
OUTPUT_FOLDER = "scan_reports"

INDIVIDUAL_REPORT_FORMAT = "{book_name}_report.json"
BATCH_SUMMARY_FORMAT = "batch_summary_{timestamp}.json"


# =============================================================================
# CATEGORY-SPECIFIC SETTINGS
# =============================================================================

VIOLENCE_REQUIRES_ACTION = True
VIOLENCE_ACTION_PATTERNS = [
    r"\b(murdered|killing|stabbed|shot (him|her|them)|slaughtered)\b",
    r"\b(blood.*spilled|corpse|mutilated|decapitated)\b",
]

LGBT_REQUIRES_CONTEXT = True
LGBT_CONTEXT_PATTERNS = [
    r"\b(same-sex|gay|lesbian) (marriage|couple|relationship)\b",
    r"\b(gender identity|transgender)\b",
]

DRUGS_ALCOHOL_REQUIRES_CONSUMPTION = True
DRUGS_ALCOHOL_CONSUMPTION_PATTERNS = [
    r"\b(intoxicated|hammered)\b",
    r"\b(smoking|snorting|injecting)\b",
]


# =============================================================================
# DISPLAY SETTINGS
# =============================================================================

SHOW_PROGRESS_BAR = True
SHOW_CHAPTER_PROGRESS = True
SHOW_DETAILED_STATS = True

EMOJI_BOOK = "üìñ"
EMOJI_REPORT = "üìä"
EMOJI_HIGH_CONFIDENCE = "üî¥"
EMOJI_MODERATE_CONFIDENCE = "üü°"
EMOJI_LOW_CONFIDENCE = "üü¢"
EMOJI_SUCCESS = "‚úì"
EMOJI_ERROR = "‚úó"


# =============================================================================
# ADVANCED SETTINGS
# =============================================================================

AI_MODEL_MAX_TEXT_LENGTH = 500
DEFAULT_KEYWORD_CONFIDENCE = 0.5
ENABLE_MODEL_CACHING = True
SHOW_PERFORMANCE_STATS = True
TRACK_SCAN_TIME = True


# =============================================================================
# PHASE 3 SUMMARY DISPLAY
# =============================================================================

print(f"\n{'='*60}")
print(f"PHASE 3 CONFIGURATION")
print(f"{'='*60}")
print(f"Optimization Level: {PHASE3_LEVEL}")
print()

if PHASE3_LEVEL == "A":
    print(f"üõ°Ô∏è  SAFE MODE (Option A)")
    print(f"  ‚úÖ Enhanced keyword analysis")
    print(f"  ‚úÖ Improved confidence scoring")
    print(f"  ‚úÖ Custom violence detector (200MB)")
    print(f"  ‚úÖ Smart caching")
    print(f"  üìä Expected VRAM: 3.2GB")
    print(f"  üéØ Accuracy: +10-13%")
    print(f"  ‚ö° Speed: Same or faster")
elif PHASE3_LEVEL == "B":
    print(f"‚öñÔ∏è  BALANCED MODE (Option B)")
    print(f"  ‚úÖ All Option A features")
    print(f"  ‚úÖ 8-bit model quantization")
    print(f"  ‚úÖ Batch processing (4x)")
    print(f"  üìä Expected VRAM: 2.0GB")
    print(f"  üéØ Accuracy: +10-15%")
    print(f"  ‚ö° Speed: 20% faster")
elif PHASE3_LEVEL == "C":
    print(f"üöÄ MAXIMUM MODE (Option C)")
    print(f"  ‚úÖ All Option B features")
    print(f"  ‚úÖ 4-bit quantization")
    print(f"  ‚úÖ Quantized Llama Guard")
    print(f"  üìä Expected VRAM: 2.5GB")
    print(f"  üéØ Accuracy: +15-20%")
    print(f"  ‚ö° Speed: Same as Option A")

print()
if HAS_GPU:
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {vram_gb:.1f} GB")
else:
    print(f"GPU: Not available")

print(f"\nActive Models:")
print(f"  - Toxic-BERT: ‚úÖ" + (" (quantized)" if USE_MODEL_QUANTIZATION else ""))
print(f"  - RoBERTa Hate Speech: ‚úÖ" + (" (quantized)" if USE_MODEL_QUANTIZATION else ""))
print(f"  - Twitter-RoBERTa Sentiment: ‚úÖ" + (" (quantized)" if USE_MODEL_QUANTIZATION else ""))

if CUSTOM_VIOLENCE_DETECTOR:
    print(f"  - Custom Violence Detector: ‚úÖ")

if USE_QUANTIZED_LLAMA_GUARD:
    print(f"  - Llama Guard 3-1B: ‚úÖ (4-bit quantized)")
elif USE_LLAMA_GUARD:
    print(f"  - Llama Guard 3-1B: ‚úÖ (full)")
else:
    print(f"  - Llama Guard 3-1B: ‚ùå (disabled)")

print(f"\nTo change optimization level:")
print(f"  Edit scanner_settings.py")
print(f"  Set PHASE3_LEVEL = \"A\", \"B\", or \"C\"")
print(f"{'='*60}\n")
